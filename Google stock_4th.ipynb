{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5332025c-6ea4-4433-9521-d665027bc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3693069-7d4d-498e-9208-b1b1b33607cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"C:/Users/Pratik/Desktop/DL-LPV/Google_Stock_Test.csv\")\n",
    "train_df=pd.read_csv(\"C:/Users/Pratik/Desktop/DL-LPV/Google_Stock_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab34268-0652-4157-883f-2d283cce9074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>89.589996</td>\n",
       "      <td>91.050003</td>\n",
       "      <td>88.519997</td>\n",
       "      <td>89.120003</td>\n",
       "      <td>89.120003</td>\n",
       "      <td>28131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>90.349998</td>\n",
       "      <td>90.650002</td>\n",
       "      <td>87.269997</td>\n",
       "      <td>88.080002</td>\n",
       "      <td>88.080002</td>\n",
       "      <td>34854800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>87.470001</td>\n",
       "      <td>87.570000</td>\n",
       "      <td>85.900002</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>27194400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>87.690002</td>\n",
       "      <td>84.860001</td>\n",
       "      <td>87.339996</td>\n",
       "      <td>87.339996</td>\n",
       "      <td>41381500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>88.360001</td>\n",
       "      <td>90.050003</td>\n",
       "      <td>87.860001</td>\n",
       "      <td>88.019997</td>\n",
       "      <td>88.019997</td>\n",
       "      <td>29003900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2023-01-03  89.589996  91.050003  88.519997  89.120003  89.120003  28131200\n",
       "1  2023-01-04  90.349998  90.650002  87.269997  88.080002  88.080002  34854800\n",
       "2  2023-01-05  87.470001  87.570000  85.900002  86.199997  86.199997  27194400\n",
       "3  2023-01-06  86.790001  87.690002  84.860001  87.339996  87.339996  41381500\n",
       "4  2023-01-09  88.360001  90.050003  87.860001  88.019997  88.019997  29003900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d034e47-93ff-4d0d-be80-71aad566dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.689439</td>\n",
       "      <td>15.753504</td>\n",
       "      <td>15.621622</td>\n",
       "      <td>15.684434</td>\n",
       "      <td>15.684434</td>\n",
       "      <td>78169752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>15.695195</td>\n",
       "      <td>15.711712</td>\n",
       "      <td>15.554054</td>\n",
       "      <td>15.615365</td>\n",
       "      <td>15.615365</td>\n",
       "      <td>120067812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>15.662162</td>\n",
       "      <td>15.662162</td>\n",
       "      <td>15.174174</td>\n",
       "      <td>15.221722</td>\n",
       "      <td>15.221722</td>\n",
       "      <td>158988852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>15.250250</td>\n",
       "      <td>15.265265</td>\n",
       "      <td>14.831081</td>\n",
       "      <td>14.867367</td>\n",
       "      <td>14.867367</td>\n",
       "      <td>256315428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>15.096346</td>\n",
       "      <td>14.742492</td>\n",
       "      <td>15.065566</td>\n",
       "      <td>15.065566</td>\n",
       "      <td>188783028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2010-01-04  15.689439  15.753504  15.621622  15.684434  15.684434   \n",
       "1  2010-01-05  15.695195  15.711712  15.554054  15.615365  15.615365   \n",
       "2  2010-01-06  15.662162  15.662162  15.174174  15.221722  15.221722   \n",
       "3  2010-01-07  15.250250  15.265265  14.831081  14.867367  14.867367   \n",
       "4  2010-01-08  14.814815  15.096346  14.742492  15.065566  15.065566   \n",
       "\n",
       "      Volume  \n",
       "0   78169752  \n",
       "1  120067812  \n",
       "2  158988852  \n",
       "3  256315428  \n",
       "4  188783028  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fde163-01f5-4682-931d-c32aad5b0818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd7a6f7-e3a9-4073-b9d4-f193ae0e8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    " # # Convert 'Close' column to string type and remove commas\n",
    " # train_df['Close'] = train_df['Close'].astype(str).str.replace(',', '').astype(float)\n",
    " # test_df['Close'] = test_df['Close'].astype(str).str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e721cf3-90e8-4733-b4c7-cbaab1d17ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Normalize the training and testing data separately\n",
    "train_scaler = MinMaxScaler()\n",
    "train_df['Normalized Close'] = train_scaler.fit_transform(train_df['Close'].values.reshape(-1, 1))\n",
    "test_scaler = MinMaxScaler()\n",
    "test_df['Normalized Close'] = test_scaler.fit_transform(test_df['Close'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d370896-cdb1-4e98-b2df-42d1df7e8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert the data to the appropriate format for RNN\n",
    " x_train = train_df['Normalized Close'].values[:-1].reshape(-1, 1, 1)\n",
    " y_train = train_df['Normalized Close'].values[1:].reshape(-1, 1, 1)\n",
    " x_test = test_df['Normalized Close'].values[:-1].reshape(-1, 1, 1)\n",
    " y_test = test_df['Normalized Close'].values[1:].reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12cbae67-69e6-431b-919f-83f8ee4ea75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (3271, 1, 1)\n",
      "y_train shape:  (3271, 1, 1)\n",
      "x_test shape:  (142, 1, 1)\n",
      "y_test shape:  (142, 1, 1)\n"
     ]
    }
   ],
   "source": [
    " print(\"x_train shape: \",x_train.shape)\n",
    " print(\"y_train shape: \",y_train.shape)\n",
    " print(\"x_test shape: \",x_test.shape)\n",
    " print(\"y_test shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d29521d-2bfd-4846-93af-bd7374b12c17",
   "metadata": {},
   "outputs": [],
   "source": [
    " from keras.models import Sequential\n",
    " from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18079236-ee61-4964-99b3-329beccbebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m96\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m5\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> (404.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101\u001b[0m (404.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> (404.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101\u001b[0m (404.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6e5f11-7884-48d2-b74e-3106ae6fe4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0363\n",
      "Epoch 2/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.6406e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.2222e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0085e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0155e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.9527e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1000us/step - loss: 9.4628e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.6050e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.6910e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.0629e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.5126e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.1138e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.0664e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 996us/step - loss: 9.5009e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.6099e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 8.2580e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 9.6008e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 1.0486e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.6655e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0222e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.6560e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.1330e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.8552e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.3704e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.0618e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.8574e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.8925e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.2289e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.5665e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.5929e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.1637e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.1134e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.4049e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.5425e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.0713e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.3587e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.0485e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.8201e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 984us/step - loss: 8.9409e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.6404e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 989us/step - loss: 8.6918e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 995us/step - loss: 8.5109e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 977us/step - loss: 8.6822e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.5241e-05  \n",
      "Epoch 45/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 980us/step - loss: 7.5547e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.0598e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 986us/step - loss: 7.6401e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.9420e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.8916e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.7008e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 984us/step - loss: 9.8164e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.1788e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.6803e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 963us/step - loss: 8.3968e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.3642e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.1744e-05  \n",
      "Epoch 57/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.0412e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0034e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 983us/step - loss: 8.3015e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 7.1161e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.3041e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.9840e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 995us/step - loss: 7.6870e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 8.4076e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.5749e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.9499e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.6005e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 7.6404e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.2083e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.1418e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.7187e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.1242e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.8467e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.2349e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 995us/step - loss: 8.7504e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.2269e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 994us/step - loss: 7.4042e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.6726e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.5680e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.6383e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.0153e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.8078e-05  \n",
      "Epoch 83/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.3245e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.2211e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.3773e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.8185e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.3436e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.8292e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.7418e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.7315e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.9129e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.7040e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.0546e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.8566e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 7.2750e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.5952e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.8038e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.6275e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 8.2043e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m3271/3271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.5170e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x235357472d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec50e8d-6e90-47c7-a70f-5293935bb2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027  \n",
      "Testing loss:  0.002377114724367857\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(x_test, y_test)\n",
    "print('Testing loss: ', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141c7697-7d7a-4eab-849d-24e40f0a4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    " y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb9fe7f-57ac-4e7a-b9f6-581829b2ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the normalized values to get the actual values\n",
    "y_test_actual = test_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_actual = test_scaler.inverse_transform(y_pred.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b29f042-5a61-47f6-9d14-ba1b66b8839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f858461-ce77-476a-80f1-4ab557cfafb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual value: 86.20\n",
      "Predicted value: 88.06\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual value: {:.2f}\".format(y_test_actual[i][0]))\n",
    "print(\"Predicted value: {:.2f}\".format(y_pred_actual[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22a1a1-f940-403d-89b3-b85c1240834d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
